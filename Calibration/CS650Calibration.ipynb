{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Bring in libraries and dataframes and set indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File D:\\GitHubRepos\\StonySoilLysimeters\\Calibration\\CS650Calibration_CS650Callibration.dat does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3c8ff57055a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m                          \u001b[0mskiprows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#leave out rows 1, 3 and 4 which have redundant information\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                          \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#Use the first column, which is Date, as an index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                          na_values = 'NAN')\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#Bring in index data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    472\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1072\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3173)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:5912)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File D:\\GitHubRepos\\StonySoilLysimeters\\Calibration\\CS650Calibration_CS650Callibration.dat does not exist"
     ]
    }
   ],
   "source": [
    "#Read in data\n",
    "AllData=pd.read_csv('D:\\GitHubRepos\\StonySoilLysimeters\\Calibration\\CS650Calibration_CS650Callibration.dat', #specify file path for data to read in\n",
    "                         parse_dates=True, #tell the function to parse date columns to datetime formats\n",
    "                         dayfirst=True, #tell the function that the day is before the year in the data i.e format='%d/%m/%Y %H:%M'\n",
    "                         skiprows = [0,2,3], #leave out rows 1, 3 and 4 which have redundant information\n",
    "                         index_col = 0, #Use the first column, which is Date, as an index\n",
    "                         na_values = 'NAN')\n",
    "\n",
    "#Bring in index data\n",
    "AllDataIndex=pd.read_csv('D:\\GitHubRepos\\StonySoilLysimeters\\Calibration\\CalibrationWater&TempIndex.csv',\n",
    "                         index_col = 0)\n",
    "#Apply indexes to data\n",
    "AllDataTransposed = AllData.transpose()\n",
    "AllDataIndexed = pd.concat([AllDataIndex,AllDataTransposed], axis=1)\n",
    "AllDataIndexed.index.name='ColumnHeader'\n",
    "AllDataIndexed.set_index(['Measurement','Treatment','Block','Sensor','Units','Summary','SDIport','SDIaddress'], \n",
    "                        append=False, inplace=True)\n",
    "AllDataIndexed.sort(inplace=True)\n",
    "Data=AllDataIndexed.transpose()\n",
    "Data.index = Data.index.to_datetime()  ## for some reason the concat function changes the data type on the date indes so need to change it back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set time slice to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta #Import function needed for doing date deltas \n",
    "EndDate = Data.index.max()  #Set end of series as most recent date in file\n",
    "EndDateString = EndDate.strftime(\"%Y-%m-%d\")  #Turn this to a string\n",
    "PlotDuration = 10\n",
    "#Set the duration that you want to graph for\n",
    "StartDate = EndDate - timedelta(weeks=PlotDuration)       #Set start date the specified duration before the end date \n",
    "StartDateString = StartDate.strftime(\"%Y-%m-%d\")           #Turn that into a string\n",
    "EndDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AllData['BattV_Avg'].plot(ylim=(11,14))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data.VolumetricWaterContent.plot(figsize=(18,10),style=['g-','g-','g-','y-','y-','y-','b-','b-','b-','k-','k-','k-','r-','r-','r-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataMeans =  Data.VolumetricWaterContent.groupby(level=['Treatment'],axis=1).mean()\n",
    "DataMeans.plot(figsize=(18,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Bring in gravometric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GravometricData = pd.read_excel('C:\\GitHubRepos\\StonySoilLysimeters\\Calibration\\SoilWeightData.xlsx', sheetname='ForPython')\n",
    "GravometricData.set_index(['Plot','Trt','TrtNo', 'Rep'], inplace=True)\n",
    "GWCData=GravometricData.transpose()  #Gravometric water content\n",
    "Dates =   GWCData.index.tolist()    #List dates when containers were weighed\n",
    "TDRData = Data.VolumetricWaterContent.ix[Dates,:]   #Set up a dateframe with CS650 data for the same dates and times\n",
    "\n",
    "DBD = pd.read_excel('C:\\GitHubRepos\\StonySoilLysimeters\\Calibration\\SoilWeightData.xlsx', sheetname='PythonBD')\n",
    "DBD.set_index('Plot', inplace=True)\n",
    "DBDData = DBD.transpose()  #Soil Dry Bulk Density Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GWCData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Calculated volumetric water content from gravometric water content and soil dry bulk density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VWCData = pd.DataFrame(index = GWCData.index, columns = GWCData.columns)  #Set up empty dataframe with the same index and column structure as TDR data\n",
    "for X in range (1,16): \n",
    "    Plot = 'P'+ np.str(X)\n",
    "    VWCData.ix[:,Plot] = GWCData.ix[:,X-1].multiply(DBDData.ix['DBD',Plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate mean water contents from TDR\n",
    "TDRMeans = TDRData.groupby(level =['Treatment'], axis=1).mean() \n",
    "\n",
    "#calculate mean gravometric water content\n",
    "VWCMeans = VWCData.groupby(level=['Trt'],axis=1).mean()\n",
    "\n",
    "\n",
    "Fig = plt.figure(figsize=(18, 18))\n",
    "\n",
    "def MakePlot(Position, Horizon, HorizonLabel, Ymax):\n",
    "        Fig.add_subplot(3,2,Position, color_cycle=['r','k'])\n",
    "        plt.title(HorizonLabel, fontsize=28);\n",
    "        plt.plot(TDRMeans.index, TDRMeans.ix[:,Horizon], '-', linewidth = 4, label='cS650' );\n",
    "        plt.plot(VWCMeans.index, VWCMeans.ix[:,Horizon], 'o', markersize=20, label='Weighed' );\n",
    "        plt.ylabel('mm/mm', fontsize=22);\n",
    "        plt.tick_params(labelsize=16);\n",
    "        plt.ylim(0,Ymax);\n",
    "        plt.legend(loc=1, fontsize=13, title='Volumetric Water Content')\n",
    "        return;\n",
    "\n",
    "MakePlot(1,'Gravel','Gravel', 0.4) \n",
    "MakePlot(2, 'SubSoil_0', 'Sub Soil', 0.4)\n",
    "MakePlot(3, 'TopSoil_0', 'TopSoil (0% Stones)', 0.4)\n",
    "MakePlot(4, 'TopSoil_30','Top Soil (30% Stones)', 0.4)\n",
    "MakePlot(5, 'TopSoil_50', 'Top Soil (50% Stones)', 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Regress the data for each treatment to get callibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HorizonLables = pd.Series(VWCMeans.columns,name='Horizon')\n",
    "#Add in two horizon labels for sub soil horizions that were not included in calibration\n",
    "HorizonLables[5] = 'SubSoil_30'\n",
    "HorizonLables[6] = 'SubSoil_50'\n",
    "HorizonCoefficients = pd.DataFrame(0,index=HorizonLables,columns=['Slope','Intercept', 'LL', 'DUL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TDRMeans.Gravel[:'2015-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Draw a graph with mean data\n",
    "plt.figure(figsize=(14, 10));\n",
    "plt.title('TDR check', fontsize=28);\n",
    "plt.scatter(TDRMeans.Gravel[:'2015-04-01'], VWCMeans.Gravel[:'2015-04-01'], c='r', s=90, label='Gravel' );\n",
    "plt.scatter(TDRMeans.SubSoil_0[:'2015-04-01'], VWCMeans.SubSoil_0[:'2015-04-01'], c='g', s=90, label='Sub Soil (0% Stones');\n",
    "plt.scatter(TDRMeans.TopSoil_0[:'2015-04-01'], VWCMeans.TopSoil_0[:'2015-04-01'], c='b', s=90, label='Top Soil (0% Stones)');\n",
    "plt.scatter(TDRMeans.TopSoil_30[:'2015-04-01'], VWCMeans.TopSoil_30[:'2015-04-01'], c='y', s=90, label='Top Soil (30% Stones)');\n",
    "plt.scatter(TDRMeans.TopSoil_50[:'2015-04-01'], VWCMeans.TopSoil_50[:'2015-04-01'], c='k', s=90, label='Top Soil (50% Stones)');\n",
    "plt.plot([0,0.5], [0,0.5], 'k-', linewidth = 3, label = 'y=x')\n",
    "plt.ylim(0,0.4);\n",
    "plt.xlim(0,0.4);\n",
    "plt.xlabel('VWC (CS650)', fontsize=22);\n",
    "plt.ylabel('VWC (weighing)', fontsize=22);\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "#Fit regressions to each treatment for the dry down data\n",
    "for X in range(0,5):\n",
    "    Treatment = HorizonLables[X]\n",
    "    ModTemp = sm.regression.linear_model.OLS(VWCMeans.ix[:'2015-04-01',Treatment],  # Y variable\n",
    "                                        sm.add_constant(TDRMeans.ix[:'2015-04-01',Treatment]), # X variable\n",
    "                                        missing='drop',                                     # ignor and data where one value is missing\n",
    "                                        hasconst=False) \n",
    "    RegCalib = ModTemp.fit();  # fit models parameters\n",
    "\n",
    "#Add regressions onto graph\n",
    "    xmin = TDRMeans.ix[:'2015-04-01',Treatment].min()\n",
    "    xmax = TDRMeans.ix[:'2015-04-01',Treatment].max()\n",
    "    Regres = RegCalib\n",
    "    VWC_x = [xmin,xmax];\n",
    "    VWC_y_fits = [Regres.params.const + xmin * Regres.params.get_value(Treatment), Regres.params.const + xmax * Regres.params.get_value(Treatment)];\n",
    "    plt.plot(VWC_x, VWC_y_fits, 'k--', lw=4);\n",
    "    \n",
    "#Assign coeffients to dataframe\n",
    "    HorizonCoefficients.ix[Treatment,'Slope'] = Regres.params.get_value(Treatment)\n",
    "    HorizonCoefficients.ix[Treatment,'Intercept'] = Regres.params.const\n",
    "    \n",
    "#Add wet up data onto graph\n",
    "#plt.scatter(TDRMeans.Gravel['2015-04-01':], VWCMeans.Gravel['2015-04-01':], c='r', s=90, label='Wetup Gravel', marker='*');\n",
    "#plt.scatter(TDRMeans.SubSoil_0['2015-04-01':], VWCMeans.SubSoil_0['2015-04-01':], c='g', s=90, label='Wetup Sub Soil (0% Stones)', marker='*');\n",
    "#plt.scatter(TDRMeans.TopSoil_0['2015-04-01':], VWCMeans.TopSoil_0['2015-04-01':], c='b', s=90, label='Wetup Top Soil (0% Stones)', marker='*');\n",
    "#plt.scatter(TDRMeans.TopSoil_30['2015-04-01':], VWCMeans.TopSoil_30['2015-04-01':], c='y', s=90, label='Wetup Top Soil (30% Stones)', marker='*');\n",
    "#plt.scatter(TDRMeans.TopSoil_50['2015-04-01':], VWCMeans.TopSoil_50['2015-04-01':], c='k', s=90, label='Wetup Top Soil (50% Stones)', marker='*');\n",
    "\n",
    "plt.legend(loc=0, fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VWCData.index = VWCData.index.to_datetime() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VWCDataUpper = VWCData[:'2015-04-01'].max(axis=0)\n",
    "VWCDataLower = VWCData[:'2015-04-01'].min(axis=0)\n",
    "PAWC = VWCDataUpper - VWCDataLower\n",
    "PAWCLiters = PAWC * 35 # crates are 35 liters\n",
    "RewettingVolumes = PAWCLiters/5\n",
    "RewettingVolumes.groupby(level='Trt').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HorizonLL = VWCDataLower.groupby(level='Trt').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Estimate slope for sub soil horizions in relation to the stone effect from top soil horizons\n",
    "HorizonCoefficients.ix['SubSoil_30','Slope'] = HorizonCoefficients.ix['SubSoil_0','Slope'] - (HorizonCoefficients.ix['TopSoil_30','Slope']-HorizonCoefficients.ix['TopSoil_0','Slope'])\n",
    "HorizonCoefficients.ix['SubSoil_50','Slope'] = HorizonCoefficients.ix['SubSoil_0','Slope'] - (HorizonCoefficients.ix['TopSoil_50','Slope']-HorizonCoefficients.ix['TopSoil_0','Slope'])\n",
    "HorizonCoefficients.ix['SubSoil_30','Intercept'] = HorizonCoefficients.ix['SubSoil_0','Intercept'] - (HorizonCoefficients.ix['TopSoil_30','Intercept']-HorizonCoefficients.ix['TopSoil_0','Intercept'])\n",
    "HorizonCoefficients.ix['SubSoil_50','Intercept'] = HorizonCoefficients.ix['SubSoil_0','Intercept'] - (HorizonCoefficients.ix['TopSoil_50','Intercept']-HorizonCoefficients.ix['TopSoil_0','Intercept'])\n",
    "\n",
    "#Set Lower limit values for each horizon type\n",
    "HorizonCoefficients.LL = HorizonLL  #use lowest measured values for observed horizions\n",
    "HorizonCoefficients.ix['SubSoil_30','LL'] = HorizonCoefficients.ix['SubSoil_0','LL'] * 0.7  #Estamate for stony sub soils based on stone free value and stone volume\n",
    "HorizonCoefficients.ix['SubSoil_50','LL'] = HorizonCoefficients.ix['SubSoil_0','LL'] * 0.5\n",
    "\n",
    "#Set drained upper limits for each horizion type\n",
    "HorizonCoefficients.ix['Gravel','DUL'] = 0.12\n",
    "SubSoilDUL = 0.32\n",
    "TopSoilDUL = 0.35\n",
    "\n",
    "HorizonCoefficients.ix['SubSoil_0','DUL'] = SubSoilDUL\n",
    "HorizonCoefficients.ix['TopSoil_0','DUL'] = TopSoilDUL \n",
    "HorizonCoefficients.ix['SubSoil_30','DUL'] = SubSoilDUL * 0.7\n",
    "HorizonCoefficients.ix['TopSoil_30','DUL'] = TopSoilDUL * 0.7\n",
    "HorizonCoefficients.ix['SubSoil_50','DUL'] = SubSoilDUL * 0.5\n",
    "HorizonCoefficients.ix['TopSoil_50','DUL'] = TopSoilDUL * 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HorizonCoefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HorizonCoefficients.to_pickle('C:\\GitHubRepos\\StonySoilLysimeters\\Calibration\\CS650Calibration.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!gist -p -d \"Setting up CSC650 calibration for Export\" CS650Calibration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!gist -u https://gist.github.com/2b9d3cd05aefe707c181 CS650Calibration.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
